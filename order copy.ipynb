{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orden tesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers.process_input import datasetPreprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de carpetas para futuras ejecuciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos\n",
    "\n",
    "- baks: Contiene los arhcivos de indy y de loco preprocesados hasta la etapa de baks (ambos tienen SUA, MUA e y_task).\n",
    "- rounded: Mismos archivos de indy y loco pero con SUA y MUA redondeados al primer decimal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando carpeta data/baks y data/rounded\n",
    "dirname_baks = os.path.join('transformers/data', 'baks')\n",
    "dirname_rounded = os.path.join('transformers/data', 'rounded')\n",
    "\n",
    "# Si no existe crea las carpetas\n",
    "os.makedirs(dirname_baks, exist_ok=True)\n",
    "os.makedirs(dirname_rounded, exist_ok=True)\n",
    "\n",
    "# Creo también carpetas para indy y loco dentro de baks y rounded\n",
    "os.makedirs(f'{dirname_baks}/indy', exist_ok=True)\n",
    "os.makedirs(f'{dirname_baks}/loco', exist_ok=True)\n",
    "os.makedirs(f'{dirname_rounded}/indy', exist_ok=True)\n",
    "os.makedirs(f'{dirname_rounded}/loco', exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de baks ya se tendrán los archivos de indy y loco.\n",
    "\n",
    "Para rounded se tendrá que ejecutar la función datasetPreprocessing de processinput.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total archivos baks/indy: 37\n",
      "Total archivos baks/loco: 10\n"
     ]
    }
   ],
   "source": [
    "# Cantidad archivos carpeta baks/indy:37 y baks/loco:10\n",
    "print(\"Total archivos baks/indy:\", len(os.listdir(f'{dirname_baks}/indy')))\n",
    "print(\"Total archivos baks/loco:\", len(os.listdir(f'{dirname_baks}/loco')))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opt\n",
    "\n",
    "Para cuando se ejecute el optimizador de parámetros se requerirán las siguientes carpetas base:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- opt: Todos los resultados obtenidos del optimizador.\n",
    "\n",
    "En su interior:\n",
    "- only_velocity: Se trabaja solo con la velocidad como salida.\n",
    "- all_ytask: Se trabaja con la posición, velocidad y aceleración como salida.\n",
    "\n",
    "Cada una de ellas tendrán:\n",
    "- normalized: Datos de indy y loco para SUA y MUA normalizados.\n",
    "- not_normalized: Datos de indy y loco para SUA y MUA NO normalizados.\n",
    "\n",
    "A su vez, esas carpetas tendrán:\n",
    "- best_weights: Los mejores pesos de indy y loco para SUA y MUA.\n",
    "- params: Los mejores hiperparámetros encontrados con el optimizador para los archivos de indy y loco para SUA y MUA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando carpetas para solo velocidad, normalizados, mejores pesos de train, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/opt/only_velocity/normalized/best_weights/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/normalized/best_weights/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/normalized/best_weights/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/normalized/best_weights/loco/mua', exist_ok=True)\n",
    "# Creando carpetas para solo velocidad, normalizados, mejores hiperparámetros, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/opt/only_velocity/normalized/params/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/normalized/params/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/normalized/params/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/normalized/params/loco/mua', exist_ok=True)\n",
    "\n",
    "# Creando carpetas para solo velocidad, NO normalizados, mejores pesos de train, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/opt/only_velocity/not_normalized/best_weights/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/not_normalized/best_weights/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/not_normalized/best_weights/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/not_normalized/best_weights/loco/mua', exist_ok=True)\n",
    "# Creando carpetas para solo velocidad, NO normalizados, mejores hiperparámetros, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/opt/only_velocity/not_normalized/params/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/not_normalized/params/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/not_normalized/params/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/only_velocity/not_normalized/params/loco/mua', exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Creando carpetas para todo y_task, normalizados, mejores pesos de train, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/opt/all_ytask/normalized/best_weights/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/normalized/best_weights/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/normalized/best_weights/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/normalized/best_weights/loco/mua', exist_ok=True)\n",
    "# Creando carpetas para todo y_task, normalizados, mejores hiperparámetros, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/opt/all_ytask/normalized/params/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/normalized/params/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/normalized/params/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/normalized/params/loco/mua', exist_ok=True)\n",
    "\n",
    "# Creando carpetas para todo y_task, NO normalizados, mejores pesos de train, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/opt/all_ytask/not_normalized/best_weights/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/not_normalized/best_weights/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/not_normalized/best_weights/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/not_normalized/best_weights/loco/mua', exist_ok=True)\n",
    "# Creando carpetas para todo y_task, NO normalizados, mejores hiperparámetros, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/opt/all_ytask/not_normalized/params/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/not_normalized/params/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/not_normalized/params/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/opt/all_ytask/not_normalized/params/loco/mua', exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval\n",
    "\n",
    "Para cuando se ejecute la evaluación del modelo con los mejores hiperparámetros encontrados por el optimizador se requerirán las siguientes carpetas base:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- eval: Todos los resultados obtenidos de la evaluación.\n",
    "\n",
    "En su interior:\n",
    "- only_velocity: Se trabaja solo con la velocidad como salida.\n",
    "- all_ytask: Se trabaja con la posición, velocidad y aceleración como salida.\n",
    "\n",
    "Cada una de ellas tendrán:\n",
    "- normalized: Datos de indy y loco para SUA y MUA normalizados.\n",
    "- not_normalized: Datos de indy y loco para SUA y MUA NO normalizados.\n",
    "\n",
    "A su vez, esas carpetas tendrán:\n",
    "- best_weights: Los mejores pesos de indy y loco para SUA y MUA.\n",
    "- results: Los resultados obtenidos finalmente para los archivos de indy y loco para SUA y MUA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando carpetas para solo velocidad, normalizados, mejores pesos de train, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/eval/only_velocity/normalized/best_weights/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/normalized/best_weights/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/normalized/best_weights/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/normalized/best_weights/loco/mua', exist_ok=True)\n",
    "# Creando carpetas para solo velocidad, normalizados, mejores hiperparámetros, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/eval/only_velocity/normalized/results/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/normalized/results/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/normalized/results/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/normalized/results/loco/mua', exist_ok=True)\n",
    "\n",
    "# Creando carpetas para solo velocidad, NO normalizados, mejores pesos de train, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/eval/only_velocity/not_normalized/best_weights/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/not_normalized/best_weights/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/not_normalized/best_weights/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/not_normalized/best_weights/loco/mua', exist_ok=True)\n",
    "# Creando carpetas para solo velocidad, NO normalizados, mejores hiperparámetros, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/eval/only_velocity/not_normalized/results/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/not_normalized/results/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/not_normalized/results/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/only_velocity/not_normalized/results/loco/mua', exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Creando carpetas para todo y_task, normalizados, mejores pesos de train, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/eval/all_ytask/normalized/best_weights/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/normalized/best_weights/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/normalized/best_weights/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/normalized/best_weights/loco/mua', exist_ok=True)\n",
    "# Creando carpetas para todo y_task, normalizados, mejores hiperparámetros, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/eval/all_ytask/normalized/results/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/normalized/results/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/normalized/results/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/normalized/results/loco/mua', exist_ok=True)\n",
    "\n",
    "# Creando carpetas para todo y_task, NO normalizados, mejores pesos de train, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/eval/all_ytask/not_normalized/best_weights/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/not_normalized/best_weights/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/not_normalized/best_weights/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/not_normalized/best_weights/loco/mua', exist_ok=True)\n",
    "# Creando carpetas para todo y_task, NO normalizados, mejores hiperparámetros, para indy y loco ambos con SUA y MUA.\n",
    "os.makedirs(f'transformers/eval/all_ytask/not_normalized/results/indy/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/not_normalized/results/indy/mua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/not_normalized/results/loco/sua', exist_ok=True)\n",
    "os.makedirs(f'transformers/eval/all_ytask/not_normalized/results/loco/mua', exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "## Averiguando min y max de los datos normalizados para hacer un vocabulario general "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " indy_20161007_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160927_04_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160420_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160411_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160622_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161026_03_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161220_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161212_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160630_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160624_03_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161005_06_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161024_03_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20170124_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160927_06_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161017_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161207_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20170131_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160407_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160930_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160418_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160916_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160627_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160426_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160915_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161006_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161025_04_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160419_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161027_03_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161206_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160930_05_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20170127_03_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161013_03_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161014_04_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160411_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20170123_02_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161011_03_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160921_01_baks_rounded_1.h5\n",
      "0.5 0.6 0.7 0.8 0.9 "
     ]
    }
   ],
   "source": [
    "from transformers.transformers_p import splitDataset3\n",
    "from transformers.process_input import readDataset\n",
    "import numpy as np\n",
    "\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'sua'\n",
    "dir_datasets = f'transformers/data/rounded/{monkey_name}' # Directorio donde se encuentran los archivos.'\n",
    "\n",
    "maxis = []\n",
    "minis = []\n",
    "\n",
    "for dataset in os.listdir('transformers/data/rounded/indy'):\n",
    "    filename_dataset = dataset\n",
    "    print(\"\\n\", filename_dataset, end=\"  \")\n",
    "    maxi_folds = []\n",
    "    mini_folds = []\n",
    "    for window in [.5, .6, .7, .8, .9]:\n",
    "        print(window, end=\" \")\n",
    "        X, Y = readDataset(f\"{dir_datasets}/{filename_dataset}\", feature, only_velocity=True)\n",
    "        _, _, _, new_vocabulary = splitDataset3(X, Y, decimal, limit_sup_train=window, limit_sup_eval=.1 , scaled=True)\n",
    "        maxi_folds.append(np.max(new_vocabulary))\n",
    "        mini_folds.append(np.min(new_vocabulary))\n",
    "    maxis.append(maxi_folds)\n",
    "    minis.append(mini_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX:  81.7\n",
      "MIN:  -3.1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "new_max = []\n",
    "new_min = []\n",
    "while i < len(maxis):\n",
    "    new_max.append(max(maxis[i]))\n",
    "    new_min.append(min(minis[i]))\n",
    "    i=i+1\n",
    "\n",
    "print(\"MAX: \", max(new_max))\n",
    "print(\"MIN: \", min(new_min))\n",
    "\n",
    "# Para todos los archivos de indy SUA, todos los folds [.5, .6, .7, .8, .9]\n",
    "# MAX:  81.7\n",
    "# MIN:  -3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " indy_20161007_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160927_04_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160420_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160411_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160622_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161026_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161220_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161212_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160630_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160624_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161005_06_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161024_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20170124_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160927_06_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161017_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161207_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20170131_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160407_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160930_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160418_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160916_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160627_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160426_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160915_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161006_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161025_04_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160419_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161027_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161206_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160930_05_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20170127_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161013_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161014_04_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160411_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20170123_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20161011_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " indy_20160921_01_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 MAX:  82.8\n",
      "MIN:  -4.2\n"
     ]
    }
   ],
   "source": [
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'mua'\n",
    "dir_datasets = f'transformers/data/rounded/{monkey_name}' # Directorio donde se encuentran los archivos.'\n",
    "\n",
    "maxis_indy_mua = []\n",
    "minis_indy_mua = []\n",
    "\n",
    "for dataset in os.listdir('transformers/data/rounded/indy'):\n",
    "    filename_dataset = dataset\n",
    "    print(\"\\n\", filename_dataset, end=\"  \")\n",
    "    maxi_folds = []\n",
    "    mini_folds = []\n",
    "    for window in [.5, .6, .7, .8, .9]:\n",
    "        print(window, end=\" \")\n",
    "        X, Y = readDataset(f\"{dir_datasets}/{filename_dataset}\", feature, only_velocity=True)\n",
    "        _, _, _, new_vocabulary = splitDataset3(X, Y, decimal, limit_sup_train=window, limit_sup_eval=.1 , scaled=True)\n",
    "        maxi_folds.append(np.max(new_vocabulary))\n",
    "        mini_folds.append(np.min(new_vocabulary))\n",
    "    maxis_indy_mua.append(maxi_folds)\n",
    "    minis_indy_mua.append(mini_folds)\n",
    "    \n",
    "i = 0\n",
    "new_max_indy_mua = []\n",
    "new_min_indy_mua = []\n",
    "while i < len(maxis_indy_mua):\n",
    "    new_max_indy_mua.append(max(maxis_indy_mua[i]))\n",
    "    new_min_indy_mua.append(min(minis_indy_mua[i]))\n",
    "    i=i+1\n",
    "\n",
    "print(\"MAX: \", max(new_max_indy_mua))\n",
    "print(\"MIN: \", min(new_min_indy_mua))\n",
    "\n",
    "# Para todos los archivos de indy MUA, todos los folds [.5, .6, .7, .8, .9]\n",
    "# MAX:  82.8\n",
    "# MIN:  -4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loco_20170216_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170228_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170217_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170214_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170302_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170213_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170210_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170215_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170227_04_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170301_05_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      "\n",
      "MAX:  81.6\n",
      "MIN:  -2.2\n"
     ]
    }
   ],
   "source": [
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'sua'\n",
    "dir_datasets = f'transformers/data/rounded/{monkey_name}' # Directorio donde se encuentran los archivos.'\n",
    "\n",
    "maxis_loco_sua = []\n",
    "minis_loco_sua = []\n",
    "\n",
    "for dataset in os.listdir('transformers/data/rounded/loco'):\n",
    "    filename_dataset = dataset\n",
    "    print(\"\\n\", filename_dataset, end=\"  \")\n",
    "    maxi_folds = []\n",
    "    mini_folds = []\n",
    "    for window in [.5, .6, .7, .8, .9]:\n",
    "        print(window, end=\" \")\n",
    "        X, Y = readDataset(f\"{dir_datasets}/{filename_dataset}\", feature, only_velocity=True)\n",
    "        _, _, _, new_vocabulary = splitDataset3(X, Y, decimal, limit_sup_train=window, limit_sup_eval=.1 , scaled=True)\n",
    "        maxi_folds.append(np.max(new_vocabulary))\n",
    "        mini_folds.append(np.min(new_vocabulary))\n",
    "    maxis_loco_sua.append(maxi_folds)\n",
    "    minis_loco_sua.append(mini_folds)\n",
    "    \n",
    "i = 0\n",
    "new_max_loco_sua = []\n",
    "new_min_loco_sua = []\n",
    "while i < len(maxis_loco_sua):\n",
    "    new_max_loco_sua.append(max(maxis_loco_sua[i]))\n",
    "    new_min_loco_sua.append(min(minis_loco_sua[i]))\n",
    "    i=i+1\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"MAX: \", max(new_max_loco_sua))\n",
    "print(\"MIN: \", min(new_min_loco_sua))\n",
    "\n",
    "# Para todos los archivos de loco SUA, todos los folds [.5, .6, .7, .8, .9]\n",
    "# MAX:  81.6\n",
    "# MIN:  -2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " loco_20170216_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170228_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170217_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170214_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170302_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170213_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170210_03_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170215_02_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170227_04_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      " loco_20170301_05_baks_rounded_1.h5  0.5 0.6 0.7 0.8 0.9 \n",
      "\n",
      "MAX:  132.7\n",
      "MIN:  -2.6\n"
     ]
    }
   ],
   "source": [
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'mua'\n",
    "dir_datasets = f'transformers/data/rounded/{monkey_name}' # Directorio donde se encuentran los archivos.'\n",
    "\n",
    "maxis_loco_mua = []\n",
    "minis_loco_mua = []\n",
    "\n",
    "for dataset in os.listdir('transformers/data/rounded/loco'):\n",
    "    filename_dataset = dataset\n",
    "    print(\"\\n\", filename_dataset, end=\"  \")\n",
    "    maxi_folds = []\n",
    "    mini_folds = []\n",
    "    for window in [.5, .6, .7, .8, .9]:\n",
    "        print(window, end=\" \")\n",
    "        X, Y = readDataset(f\"{dir_datasets}/{filename_dataset}\", feature, only_velocity=True)\n",
    "        _, _, _, new_vocabulary = splitDataset3(X, Y, decimal, limit_sup_train=window, limit_sup_eval=.1 , scaled=True)\n",
    "        maxi_folds.append(np.max(new_vocabulary))\n",
    "        mini_folds.append(np.min(new_vocabulary))\n",
    "    maxis_loco_mua.append(maxi_folds)\n",
    "    minis_loco_mua.append(mini_folds)\n",
    "    \n",
    "i = 0\n",
    "new_max_loco_mua = []\n",
    "new_min_loco_mua = []\n",
    "while i < len(maxis_loco_mua):\n",
    "    new_max_loco_mua.append(max(maxis_loco_mua[i]))\n",
    "    new_min_loco_mua.append(min(minis_loco_mua[i]))\n",
    "    i=i+1\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"MAX: \", max(new_max_loco_mua))\n",
    "print(\"MIN: \", min(new_min_loco_mua))\n",
    "\n",
    "# Para todos los archivos de loco MUA, todos los folds [.5, .6, .7, .8, .9]\n",
    "# MAX:  132.7\n",
    "# MIN:  -2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.2 132.7\n"
     ]
    }
   ],
   "source": [
    "min_global = min([min(new_min_loco_mua), min(new_min_loco_sua), min(new_min_indy_mua), min(new_min)])\n",
    "max_global = max([max(new_max_loco_mua), max(new_max_loco_sua), max(new_max_indy_mua), max(new_max)])\n",
    "print(min_global, max_global)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión:\n",
    "\n",
    "Luego de normalizar todos los archivos de indy y loco, para SUA y MUA, el valor mínimo encontrado fue 4.2 y el valor máximo de 132.7."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "## Pasos a ejecutar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redondear SUA y MUA de indy y loco, esto al decimal 1. \n",
    "Demoro aproximadamente 6 min 50 seg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal = 1\n",
    "# Para indy, si no se tienen los 37 archivos redondeados, entonces redondea todo.\n",
    "if len(os.listdir('transformers/data/rounded/indy')) < 37:\n",
    "    for filename_dataset in os.listdir('transformers/data/baks/indy'):\n",
    "        datasetPreprocessing(filepath_dataset=f\"transformers/data/baks/indy/{filename_dataset}\", filename_dataset=filename_dataset, filepath_output=\"transformers/data/rounded/indy\",  rounded_decimal=decimal)\n",
    "# Para loco, si no se tienen los 10 archivos redondeados, entonces redondea todo.\n",
    "if len(os.listdir('transformers/data/rounded/loco')) < 10:\n",
    "    for filename_dataset in os.listdir('transformers/data/baks/loco'):\n",
    "        datasetPreprocessing(filepath_dataset=f\"transformers/data/baks/loco/{filename_dataset}\", filename_dataset=filename_dataset, filepath_output=\"transformers/data/rounded/loco\",  rounded_decimal=decimal)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizar hiperparámetros\n",
    "\n",
    "Requiero las siguientes ejecuciones del archivo opt_transformers.py (en total son 16)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'sua'\n",
    "scaled = 1\n",
    "filename_dataset = 'indy_20161017_02_baks_rounded_1.h5' # archivo n°15 lista del vocabulario\n",
    "only_velocity = 1\n",
    "n_startup_trials = 1\n",
    "n_trials = 20\n",
    "timeout = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Archivo a trabajar: indy_20161017_02_baks_rounded_1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-03 22:50:28,228] A new study created in memory with name: no-name-ea7b86c4-70b8-4895-9486-d14b825b6dbe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_dim': 123, 'output_dim': 2, 'n_token': 1600, 'd_model': 120, 'd_hid': 20, 'n_layers': 2, 'n_head': 2, 'dropout': 0.1, 'batch_size': 64, 'epochs': 3, 'learning_rate': 0.03750163215864584, 'optimizer': 'RMSProp', 'timesteps': 4}\n",
      "FOLDS: 0.5\n",
      "Entrenando modelo\n",
      "El entrenamiento paro en la época 3 siendo la mejor época 2\n",
      "El entrenamiento duró 1.90 minutos\n",
      "Evaluando rendimiento del modelo\n",
      "FOLDS: 0.6\n",
      "Entrenando modelo\n",
      "El entrenamiento paro en la época 3 siendo la mejor época 3\n",
      "El entrenamiento duró 1.26 minutos\n",
      "Evaluando rendimiento del modelo\n",
      "FOLDS: 0.7\n",
      "Entrenando modelo\n",
      "El entrenamiento paro en la época 3 siendo la mejor época 3\n",
      "El entrenamiento duró 1.58 minutos\n",
      "Evaluando rendimiento del modelo\n",
      "FOLDS: 0.8\n",
      "Entrenando modelo\n",
      "El entrenamiento paro en la época 3 siendo la mejor época 3\n",
      "El entrenamiento duró 1.54 minutos\n",
      "Evaluando rendimiento del modelo\n",
      "FOLDS: 0.9\n",
      "Entrenando modelo\n",
      "El entrenamiento paro en la época 3 siendo la mejor época 2\n",
      "El entrenamiento duró 1.78 minutos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-03 23:11:55,415] Trial 0 finished with value: 123.16037959785997 and parameters: {'d_model': 120, 'n_layers': 2, 'dropout': 0.1, 'batch_size': 64, 'learning_rate': 0.03750163215864584, 'optimizer': 'RMSProp', 'timesteps': 4}. Best is trial 0 with value: 123.16037959785997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando rendimiento del modelo\n",
      "==================================================\n",
      "Resultados trial\n",
      "RMSE folds: [125.87697778 116.24006465 168.01196071 116.37725999  89.29563486]\n",
      "rmse_eval_mean:  123.16037959785997\n",
      "CC folds: [-0.01303702  0.02453947  0.05937813  0.03455548 -0.00977286]\n",
      "cc_eval_mean:  0.01913264226514702\n",
      "EVAL loss folds: [ 808197.20715766  885961.46118229 1614746.77495359  738788.05008117\n",
      "  493380.05466594]\n",
      "eval_loss_mean:  908214.7096081289\n",
      "==================================================\n",
      "Guradando trial del estudio en el archivo: transformers/opt/only_velocity/normalized/params/indy/sua/indy_20161017_02_baks_rounded_1.pkl\n",
      "Estadísticas del estudio: \n",
      "  Número de trials terminados:  1\n",
      "  Número de trials podados:  0\n",
      "  Número de trials completos:  1\n",
      "Mejores hiperparámetros:\n",
      "    d_model: 120\n",
      "    n_layers: 2\n",
      "    dropout: 0.1\n",
      "    batch_size: 64\n",
      "    learning_rate: 0.03750163215864584\n",
      "    optimizer: RMSProp\n",
      "    timesteps: 4\n",
      "    epochs: 2\n",
      "    filename: indy_20161017_02_baks_rounded_1.h5\n",
      "    best_rmse_mean: 123.16037959785997\n",
      "    rmse_eval_mean: 123.16037959785997\n",
      "    cc_eval_mean: 0.01913264226514702\n",
      "    eval_loss_mean: 908214.7096081289\n",
      "    rmse_folds: [125.87697778 116.24006465 168.01196071 116.37725999  89.29563486]\n",
      "    cc_folds: [-0.01303702  0.02453947  0.05937813  0.03455548 -0.00977286]\n",
      "    eval_loss_folds: [ 808197.20715766  885961.46118229 1614746.77495359  738788.05008117\n",
      "  493380.05466594]\n",
      "    run_time: 22.493056074778238\n",
      "    time_best_trial: 0:21:27.179822\n",
      "    history_train: [{'loss_epoch': 493966.1480797531, 'rmse_epoch': 89.33167534216174, 'cc_epoch': -0.0077533517582468025}, {'loss_epoch': 493380.0546659387, 'rmse_epoch': 89.29563485835831, 'cc_epoch': -0.00977285942213604}, {'loss_epoch': 555072.3333807194, 'rmse_epoch': 94.96748089177797, 'cc_epoch': -0.014688984393460435}]\n",
      "Guardando los mejores parámetros en el archivo: transformers/opt/only_velocity/normalized/params/indy/sua/indy_20161017_02_baks_rounded_1.json\n"
     ]
    }
   ],
   "source": [
    "# Primero ver si funciona con un archivo cualquier ejecución\n",
    "%run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "        --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "        --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "        --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### only_velocity=True; scaled=False\n",
    "1. Indy SUA solo velocidad y sin normalizar\n",
    "2. Indy MUA solo velocidad y sin normalizar\n",
    "3. Loco SUA solo velocidad y sin normalizar\n",
    "4. Loco MUA solo velocidad y sin normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (1) Indy SUA solo velocidad y sin normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'sua'\n",
    "only_velocity = 1 # solo velocidad\n",
    "scaled = 0  # sin normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir('transformers/data/rounded/indy'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (2) Indy MUA solo velocidad y sin normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'mua'\n",
    "only_velocity = 1 # solo velocidad\n",
    "scaled = 0  # sin normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir('transformers/data/rounded/indy'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (3) Loco SUA solo velocidad y sin normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'sua'\n",
    "only_velocity = 1 # solo velocidad\n",
    "scaled = 0  # sin normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir('transformers/data/rounded/loco'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (4) Loco MUA solo velocidad y sin normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'mua'\n",
    "only_velocity = 1 # solo velocidad\n",
    "scaled = 0  # sin normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir('transformers/data/rounded/loco'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (only_velocity=True; scaled=True)\n",
    "1. Indy SUA solo velocidad y con normalizar\n",
    "2. Indy MUA solo velocidad y con normalizar\n",
    "3. Loco SUA solo velocidad y con normalizar\n",
    "4. Loco MUA solo velocidad y con normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (1) Indy SUA solo velocidad y con normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'sua'\n",
    "only_velocity = 1 # solo velocidad\n",
    "scaled = 1  # con normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (2) Indy MUA solo velocidad y con normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'mua'\n",
    "only_velocity = 1 # solo velocidad\n",
    "scaled = 1  # con normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (3) Loco SUA solo velocidad y con normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'sua'\n",
    "only_velocity = 1 # solo velocidad\n",
    "scaled = 1  # con normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (4) Loco MUA solo velocidad y con normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'mua'\n",
    "only_velocity = 1 # solo velocidad\n",
    "scaled = 1  # con normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (only_velocity=False; scaled=False)\n",
    "1. Indy SUA todo y_task y sin normalizar\n",
    "2. Indy MUA todo y_task y sin normalizar\n",
    "3. Loco SUA todo y_task y sin normalizar\n",
    "4. Loco MUA todo y_task y sin normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (1) Indy SUA todo y_task y sin normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'sua'\n",
    "only_velocity = 0 # todo y_task\n",
    "scaled = 0  # sin normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (2) Indy MUA todo y_task y sin normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'mua'\n",
    "only_velocity = 0 # todo y_task\n",
    "scaled = 0  # sin normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (3) Loco SUA todo y_task y sin normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'sua'\n",
    "only_velocity = 0 # todo y_task\n",
    "scaled = 0  # sin normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (4) Loco MUA todo y_task y sin normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'mua'\n",
    "only_velocity = 0 # todo y_task\n",
    "scaled = 0  # sin normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (only_velocity=False; scaled=True)\n",
    "1. Indy SUA todo y_task y con normalizar\n",
    "2. Indy MUA todo y_task y con normalizar\n",
    "3. Loco SUA todo y_task y con normalizar\n",
    "4. Loco MUA todo y_task y con normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (1) Indy SUA todo y_task y con normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'sua'\n",
    "only_velocity = 0 # todo y_task\n",
    "scaled = 1  # con normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (2) Indy MUA todo y_task y con normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'indy'\n",
    "feature = 'mua'\n",
    "only_velocity = 0 # todo y_task\n",
    "scaled = 1  # con normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (3) Loco SUA todo y_task y con normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'sua'\n",
    "only_velocity = 0 # todo y_task\n",
    "scaled = 1  # con normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables (4) Loco MUA todo y_task y con normalizar\n",
    "decimal = 1\n",
    "monkey_name = 'loco'\n",
    "feature = 'mua'\n",
    "only_velocity = 0 # todo y_task\n",
    "scaled = 1  # con normalizar\n",
    "n_startup_trials = 10\n",
    "n_trials = 200\n",
    "timeout = 10000\n",
    "\n",
    "for dataset in os.listdir(f'transformers/data/rounded/{monkey_name}'):\n",
    "    filename_dataset = dataset\n",
    "\n",
    "    %run transformers/opt_transformers.py --decimal {decimal} --monkey_name {monkey_name} \\\n",
    "            --feature {feature} --scaled {scaled} --filename_dataset {filename_dataset} \\\n",
    "            --only_velocity {only_velocity} --n_startup_trials {n_startup_trials} \\\n",
    "            --n_trials {n_trials} --timeout {timeout}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
