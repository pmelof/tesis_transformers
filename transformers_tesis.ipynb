{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aMbNOZDqiXsC"
      },
      "source": [
        "# Transformers Tesis\n",
        "\n",
        "Continuación del desarrollo de la tesis, solo con Transformers y los archivos generados anteriormente."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5plbMRef5iBD"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "886.28s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (1.24.3)\n",
            "Requirement already satisfied: h5py in ./.venv/lib/python3.8/site-packages (3.8.0)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.8/site-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.8/site-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.8/site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.8/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.8/site-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.venv/lib/python3.8/site-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.venv/lib/python3.8/site-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.venv/lib/python3.8/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.venv/lib/python3.8/site-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.venv/lib/python3.8/site-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.venv/lib/python3.8/site-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.venv/lib/python3.8/site-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in ./.venv/lib/python3.8/site-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (44.0.0)\n",
            "Requirement already satisfied: wheel in ./.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
            "Requirement already satisfied: cmake in ./.venv/lib/python3.8/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
            "Requirement already satisfied: lit in ./.venv/lib/python3.8/site-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy h5py torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Jx8H3HTViXAT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python (v3.8.10)\n",
            "Pytorch (v2.0.1+cu117)\n"
          ]
        }
      ],
      "source": [
        "# import packages\n",
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "# from drive.MyDrive.TESIS.TESIS_FINAL.Desarrollo.bmi.utils import data_loader\n",
        "# from scipy import stats\n",
        "import platform\n",
        "# import sklearn\n",
        "import torch\n",
        "\n",
        "print(f\"Python (v{platform.python_version()})\")\n",
        "# print(f\"Sklearn (v{sklearn.__version__})\")\n",
        "print(f\"Pytorch (v{torch.__version__})\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DCNT-qi9jPJv"
      },
      "source": [
        "## Lectura dataset para un archivo:\n",
        "\n",
        "drive > MyDrive > TESIS > TESIS_FINAL > Desarrollo > data > dataset > indy_20160407_02_baks.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OUl9Ym9xs0Jo",
        "outputId": "f5d411a7-da6e-48f4-ca31-293cda53a579"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'indy_20161005_06_baks.h5'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# archivo más pequeño 4,8 \n",
        "filepath_dataset = 'indy_20161005_06_baks.h5'\n",
        "filepath_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_kHhn8J56UoQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Dataset_tesis(torch.utils.data.Dataset):\n",
        "    def __init__(self, filepath_dataset: str, feature: str, velocity: bool =True):\n",
        "        \"\"\"\n",
        "        Lee el archivo dataset para trabajar con DL.\n",
        "        ------------\n",
        "        Parámetros: \n",
        "        filepath_dataset: String\n",
        "            Dirección donde se enceuntra el dataset.\n",
        "        feature: np array\n",
        "            SUA o MUA.\n",
        "        velocity: Boolean\n",
        "            Si quiere solo la velocidad para la salida.\n",
        "        -------------\n",
        "        Retorna:\n",
        "        X: np array\n",
        "            Dataset SUA o MUA, tasa de spikes estimada.\n",
        "        y: np array\n",
        "            Si velocity=True, entonces y solo contiene velocidad x e y del mono, si velocity=False, entonces y tiene posición, velocidad y aceleración x e y del mono.\n",
        "        \"\"\"\n",
        "        with h5py.File(filepath_dataset, 'r') as f:\n",
        "            self.X = f[f'X_{feature}'][()]\n",
        "            self.y = f['y_task'][()]   \n",
        "        if velocity:\n",
        "            # select the x-y velocity components\n",
        "            self.y = self.y[:,2:4] # data shape: n x 6 (x-y position, x-y velocity, x-y acceleration)\n",
        "\n",
        "        assert len(self.X) == len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "MBE9FZhg8pLF",
        "outputId": "e660967b-cac5-40c2-9657-10d27147ee12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 9.20983517,  5.24062105,  0.        ,  0.        ,  0.        ,\n",
              "         2.03734188,  0.76785673,  2.00309387,  5.19855254,  0.7720459 ,\n",
              "         7.18813229,  0.        ,  0.        ,  9.18557871,  0.        ,\n",
              "         2.00916556,  0.7717755 ,  7.07515127,  3.52485634,  0.77222477,\n",
              "         0.        ,  5.27834563,  2.02913591,  0.        ,  0.76401624,\n",
              "         3.52105503,  2.01591345,  0.77329827,  7.07939913,  0.76122755,\n",
              "         0.        ,  0.76925464,  2.03552179,  0.76916057,  0.7504905 ,\n",
              "         5.2603572 ,  0.        ,  7.01707473,  0.        ,  0.        ,\n",
              "         0.        ,  3.54606191,  3.46932884,  0.        ,  0.75119236,\n",
              "         0.77326562,  0.77082073,  0.        ,  0.7726312 ,  0.75508565,\n",
              "         0.        ,  0.76629387,  0.        ,  0.75198997,  0.        ,\n",
              "        11.49041909,  0.        ,  0.        ,  0.        ,  3.48744758,\n",
              "         3.45897978,  3.55597981,  0.76249352,  2.03660978,  3.53303551,\n",
              "         0.        ,  0.        ,  0.76948741,  0.        ,  0.76826072,\n",
              "         0.77330558,  0.        ,  0.        ,  3.52892851,  3.40576598,\n",
              "         0.        ,  0.        ,  3.52600086,  0.77212196,  0.        ,\n",
              "         8.94345386,  0.        ,  0.        ,  0.        ,  9.01592608,\n",
              "         3.48487021,  0.76105489,  3.48673392,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.77314789,  0.77294744,  5.12315614,\n",
              "         7.13084447,  0.        ,  0.        ,  1.98752901,  7.09073154,\n",
              "         5.19001097,  0.76254648,  0.        ,  0.        ,  0.77339115,\n",
              "         0.77334616,  1.9905586 ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  0.77309719,  0.        , 11.11065149, 15.56299834,\n",
              "         0.        ]),\n",
              " array([-1.5632198 ,  4.13259506]))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# prueba\n",
        "ds = Dataset_tesis(filepath_dataset, \"sua\")\n",
        "display(ds[0])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CF1xHZHw--v8"
      },
      "source": [
        "### Iterar sobre los datos\n",
        "\n",
        "Dado un Dataset, sea hecho por nosotros o uno predefinido, iterar sobre los datos es muy sencillo. Simplemente tenemos que crear un objeto DataLoader que toma como argumento el Dataset y definir el batch size con que queremos trabajar.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0rB_JVD--1oD"
      },
      "source": [
        "Este código iterará por todos los batches de ejemplos de nuestro dataset y parará cuando se acaben. Es decir, esto corre por una **época**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofsFeqYc9gv_",
        "outputId": "214e4847-7f94-4e4f-ed40-df372d3e4e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 116]) tensor([[-1.5632e+00,  4.1326e+00],\n",
            "        [-4.9747e-01,  2.9586e+00],\n",
            "        [-2.9077e-01,  1.5623e+00],\n",
            "        [-2.8652e+00,  2.9060e+00],\n",
            "        [-1.2743e+01,  1.2830e+01],\n",
            "        [ 1.6147e+00, -1.1295e+00],\n",
            "        [-1.6560e+01,  1.4538e+01],\n",
            "        [-1.4289e+01,  1.4912e+01],\n",
            "        [-3.3338e+01,  4.4084e+01],\n",
            "        [-5.2631e+01,  1.3322e+02],\n",
            "        [-8.4908e+00,  2.5790e+02],\n",
            "        [-1.2324e+02,  1.3903e+02],\n",
            "        [-2.0541e+01, -2.9118e+00],\n",
            "        [-1.1909e+01, -3.2436e+00],\n",
            "        [-1.6900e+01,  2.4566e+00],\n",
            "        [-2.1415e+01, -5.0318e+01],\n",
            "        [-1.4349e+00,  6.7594e+00],\n",
            "        [ 2.9231e-01,  1.7495e+00],\n",
            "        [-6.6488e+00,  4.2459e+00],\n",
            "        [ 3.7126e+00, -2.1089e+00],\n",
            "        [ 1.5310e+02, -1.0968e+02],\n",
            "        [ 3.0639e+02, -2.1895e+02],\n",
            "        [ 1.4029e+02, -3.0010e+01],\n",
            "        [-4.3187e+01,  1.0594e+01],\n",
            "        [ 3.2984e+01, -3.2205e+01],\n",
            "        [-1.9657e+00,  2.0390e+00],\n",
            "        [ 2.7659e-01, -2.9754e-01],\n",
            "        [ 2.3559e-01, -5.5263e+00],\n",
            "        [ 4.1276e+00, -1.4866e+00],\n",
            "        [ 1.7059e+01,  4.1247e+01],\n",
            "        [-6.9388e+01,  1.3746e+02],\n",
            "        [ 2.6812e+01, -2.8224e+01]], dtype=torch.float64)\n",
            "torch.Size([32, 116]) tensor([[ 1.4627e+01, -1.3379e+01],\n",
            "        [-1.4744e+00,  3.3392e-01],\n",
            "        [-5.9872e-02, -1.5707e+00],\n",
            "        [-8.4384e-01, -6.4962e+00],\n",
            "        [-2.6119e+01, -5.2870e+01],\n",
            "        [-1.2076e+02, -1.3242e+02],\n",
            "        [-1.1991e+02, -1.0454e+02],\n",
            "        [-1.0256e+01, -9.0275e+00],\n",
            "        [-8.8498e+00,  8.5507e+00],\n",
            "        [-1.6113e+01,  1.2974e+01],\n",
            "        [-1.1534e+00,  1.0044e+00],\n",
            "        [ 1.2251e+00, -6.4330e-01],\n",
            "        [ 1.5593e+00, -1.0601e+00],\n",
            "        [ 1.8910e-02, -5.6702e-02],\n",
            "        [-3.8967e-01,  9.3609e-02],\n",
            "        [ 7.9307e-01,  2.8217e+00],\n",
            "        [ 4.1479e+01,  9.1365e+01],\n",
            "        [ 1.1508e+02,  2.4149e+02],\n",
            "        [ 4.2360e+01,  1.1874e+02],\n",
            "        [-1.7137e+00, -3.3378e+00],\n",
            "        [-1.1715e+00,  2.6683e+00],\n",
            "        [-1.8033e+00,  2.5575e+00],\n",
            "        [ 5.7761e+00,  2.8372e+01],\n",
            "        [ 1.3816e+01,  3.0531e+01],\n",
            "        [-2.3472e+00, -2.3546e+00],\n",
            "        [ 4.4872e-01, -1.6894e+00],\n",
            "        [-2.3833e-01, -5.8774e+00],\n",
            "        [-2.4414e+00, -1.2156e+01],\n",
            "        [-2.4746e+00,  1.5892e+00],\n",
            "        [ 3.2568e+01, -5.3437e+01],\n",
            "        [ 2.6315e+02, -1.3948e+02],\n",
            "        [ 1.4023e+00,  9.4346e+01]], dtype=torch.float64)\n",
            "torch.Size([32, 116]) tensor([[ 9.5351e+00, -2.4850e+00],\n",
            "        [ 3.1019e+00,  1.4579e+00],\n",
            "        [ 1.6317e+00, -9.5446e-01],\n",
            "        [ 1.9486e+01,  3.5784e-01],\n",
            "        [ 3.0064e+01,  3.2978e+01],\n",
            "        [ 7.5918e+00,  1.0106e+01],\n",
            "        [-2.6138e+00,  7.6493e-01],\n",
            "        [-1.4936e+00, -1.9384e+00],\n",
            "        [ 7.7048e-03, -1.1614e+01],\n",
            "        [-8.3962e+00, -6.7194e+00],\n",
            "        [ 4.2360e+00, -1.6639e+01],\n",
            "        [-4.9863e+01,  1.8649e+01],\n",
            "        [-1.3103e+02,  7.7642e+01],\n",
            "        [ 9.5531e+00,  2.0724e+01],\n",
            "        [ 2.4893e+00, -1.8662e+00],\n",
            "        [ 1.8494e-01,  1.9585e-01],\n",
            "        [ 1.0129e+00,  1.4542e+01],\n",
            "        [-7.9527e-01, -1.6383e+00],\n",
            "        [ 1.0005e+00, -2.2706e+00],\n",
            "        [ 3.7993e+00, -3.7522e+01],\n",
            "        [-3.7253e+01, -1.7433e+02],\n",
            "        [-4.8708e+01, -1.5910e+02],\n",
            "        [-5.9295e+01, -3.4551e+01],\n",
            "        [-4.5331e+01, -7.3152e+01],\n",
            "        [-2.4176e+01, -8.9267e+00],\n",
            "        [ 7.5741e-01,  4.6609e-02],\n",
            "        [ 2.6638e+00,  6.0966e-01],\n",
            "        [ 2.0643e+00, -2.0095e-01],\n",
            "        [ 2.0222e+00, -7.8146e-01],\n",
            "        [-9.2666e-01, -3.2752e-01],\n",
            "        [-9.5029e+01,  1.1571e+02],\n",
            "        [-2.4278e+02,  3.1789e+02]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dl = DataLoader(ds, batch_size=32)\n",
        "\n",
        "for i, (x, target) in enumerate(train_dl):\n",
        "    print(x.shape, target)\n",
        "    if i==2:\n",
        "      break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tFsRA74IAAUf"
      },
      "source": [
        "## Time2Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KHb7b-9KAKec"
      },
      "outputs": [],
      "source": [
        "from time2vec.periodic_activations import SineActivation, CosineActivation\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from time2vec.Pipeline import AbstractPipelineClass\n",
        "from torch import nn\n",
        "from time2vec.Model import Model\n",
        "\n",
        "class Tesis_t2v(AbstractPipelineClass):\n",
        "    def __init__(self, model, ds):\n",
        "        self.model = model\n",
        "        self.ds = ds\n",
        "    \n",
        "    def train(self):\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        train_dl = DataLoader(self.ds, batch_size=32, shuffle=False)\n",
        "\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "        num_epochs = 2\n",
        "\n",
        "        for ep in range(num_epochs):\n",
        "            for x, y in train_dl:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                y_pred = self.model(x.unsqueeze(1))\n",
        "                loss = loss_fn(y_pred, y)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                print(f\"epoch: {ep}, loss:{loss.item()}\")\n",
        "    \n",
        "    def preprocess(self, x):\n",
        "        return x\n",
        "    \n",
        "    def decorate_output(self, x):\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "70CgL83lDxJA",
        "outputId": "0a154157-5be6-4abd-e7c0-c9a5e5e7e1e7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 't1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pipe \u001b[39m=\u001b[39m Tesis_t2v(Model(\u001b[39m\"\u001b[39m\u001b[39msin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m117\u001b[39m), ds)\n\u001b[0;32m----> 2\u001b[0m pipe\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      4\u001b[0m \u001b[39m#pipe = ToyPipeline(Model(\"cos\", 12))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#pipe.train()\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[23], line 26\u001b[0m, in \u001b[0;36mTesis_t2v.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m train_dl:\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 26\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     27\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     29\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/desa/paty/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/desa/paty/time2vec/Model.py:16\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     \u001b[39m#x = x.unsqueeze(1)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1(x)\n\u001b[1;32m     17\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x)\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m~/desa/paty/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/desa/paty/time2vec/periodic_activations.py:27\u001b[0m, in \u001b[0;36mSineActivation.forward\u001b[0;34m(self, tau)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tau):\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m t2v(tau, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_features, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw0, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb0)\n",
            "File \u001b[0;32m~/desa/paty/time2vec/periodic_activations.py:10\u001b[0m, in \u001b[0;36mt2v\u001b[0;34m(tau, f, out_features, w, b, w0, b0, arg)\u001b[0m\n\u001b[1;32m      8\u001b[0m     v1 \u001b[39m=\u001b[39m f(torch\u001b[39m.\u001b[39mmatmul(tau, w) \u001b[39m+\u001b[39m b, arg)\n\u001b[1;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mprint\u001b[39m(w\u001b[39m.\u001b[39mshape, t1\u001b[39m.\u001b[39mshape, b\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m    \u001b[39m# v1 = f(torch.matmul(tau, w) + b)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m v2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(tau, w0) \u001b[39m+\u001b[39m b0\n",
            "\u001b[0;31mNameError\u001b[0m: name 't1' is not defined"
          ]
        }
      ],
      "source": [
        "pipe = Tesis_t2v(Model(\"sin\", 117), ds)\n",
        "pipe.train()\n",
        "\n",
        "#pipe = ToyPipeline(Model(\"cos\", 12))\n",
        "#pipe.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqkZ8yXmCeJx",
        "outputId": "942f02e1-b44f-46de-acf0-137b731ee7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 9.2098,  5.2406,  0.0000,  ..., 11.1107, 15.5630,  0.0000]],\n",
            "\n",
            "        [[ 5.1875,  3.5582,  0.0000,  ..., 23.2573, 13.6532,  0.0000]],\n",
            "\n",
            "        [[ 2.0124,  5.1162,  0.7699,  ..., 20.7164, 11.1603,  0.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 2.0202,  0.7734,  0.0000,  ...,  2.0309, 13.7219,  0.0000]],\n",
            "\n",
            "        [[ 3.4919,  0.0000,  1.9400,  ...,  1.9988,  6.9782,  0.0000]],\n",
            "\n",
            "        [[ 0.7712,  0.7620,  2.0408,  ...,  3.4933,  7.2585,  0.0000]]])\n"
          ]
        }
      ],
      "source": [
        "for x, y in train_dl:\n",
        "  print(x.unsqueeze(1).float())\n",
        "  break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5plbMRef5iBD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
